mod common;

use common::*;
use reqwest::StatusCode;
use serde_json::json;
use std::collections::{HashMap, HashSet};

/// Test basic queue position assignment
#[tokio::test]
async fn test_basic_queue_position() {
    TestEnvironment::validate_test_environment().await;
    
    let client = TestClient::new();
    let account_id = TestData::unique_account_id();
    let transaction_data = TestData::sample_transaction_data();
    
    let (_, position1, _) = client
        .submit_transaction_expect_success(&account_id, transaction_data.clone(), None)
        .await;
    
    let (_, position2, _) = client
        .submit_transaction_expect_success(&account_id, transaction_data, None)
        .await;
    
    assert!(position1 > 0, "First position should be positive");
    assert!(position2 > position1, "Second position should be after first");
}

/// Test queue positions are unique and sequential
#[tokio::test]
async fn test_unique_sequential_positions() {
    TestEnvironment::validate_test_environment().await;
    
    let client = TestClient::new();
    let account_id = TestData::unique_account_id();
    let transaction_data = TestData::sample_transaction_data();
    
    let mut positions = Vec::new();
    let mut transaction_ids = Vec::new();
    
    // Submit 10 transactions
    for i in 0..10 {
        let mut data = transaction_data.clone();
        data["sequence"] = json!(i);
        
        let (tx_id, position, _) = client
            .submit_transaction_expect_success(&account_id, data, None)
            .await;
        
        positions.push(position);
        transaction_ids.push(tx_id);
    }
    
    // Verify all transaction IDs are unique
    let unique_ids: std::collections::HashSet<_> = transaction_ids.iter().collect();
    assert_eq!(unique_ids.len(), transaction_ids.len(), "All transaction IDs should be unique");
    
    // Verify positions are increasing
    for i in 1..positions.len() {
        assert!(positions[i] > positions[i-1], 
                "Position {} ({}) should be greater than position {} ({})", 
                i, positions[i], i-1, positions[i-1]);
    }
}

/// Test priority affects queue position
#[tokio::test]
async fn test_priority_queue_ordering() {
    TestEnvironment::validate_test_environment().await;
    
    let client = TestClient::new();
    let account_id = TestData::unique_account_id();
    let transaction_data = TestData::sample_transaction_data();
    
    // Submit low priority first
    let (_, low_pos, _) = client
        .submit_transaction_expect_success(&account_id, transaction_data.clone(), Some(1))
        .await;
    
    // Submit high priority after
    let (_, high_pos, _) = client
        .submit_transaction_expect_success(&account_id, transaction_data.clone(), Some(10))
        .await;
    
    // Submit medium priority last
    let (_, med_pos, _) = client
        .submit_transaction_expect_success(&account_id, transaction_data, Some(5))
        .await;
    
    // All should have valid positions
    assert!(low_pos > 0);
    assert!(high_pos > 0);
    assert!(med_pos > 0);
    
    // Higher priority should have better position in processing order
    // (Implementation dependent - may be based on processing order, not queue position)
    println!("Priority positions - Low: {}, Medium: {}, High: {}", low_pos, med_pos, high_pos);
}

/// Test queue position calculation with multiple priorities
#[tokio::test]
async fn test_mixed_priority_queue() {
    TestEnvironment::validate_test_environment().await;
    
    let client = TestClient::new();
    let account_id = TestData::unique_account_id();
    let base_data = TestData::sample_transaction_data();
    
    let mut results = Vec::new();
    
    // Submit transactions with mixed priorities
    let priorities = vec![0, 5, 10, 1, 8, 3];
    for (i, priority) in priorities.iter().enumerate() {
        let mut data = base_data.clone();
        data["batch_index"] = json!(i);
        
        let (tx_id, position, est_time) = client
            .submit_transaction_expect_success(&account_id, data, Some(*priority))
            .await;
        
        results.push((tx_id, position, est_time, *priority));
    }
    
    // Verify all submissions succeeded
    assert_eq!(results.len(), 6);
    
    // Verify all positions are positive and unique
    let positions: Vec<i64> = results.iter().map(|(_, pos, _, _)| *pos).collect();
    let unique_positions: std::collections::HashSet<_> = positions.iter().collect();
    assert_eq!(unique_positions.len(), positions.len(), "All positions should be unique");
    
    for (_, pos, _, _) in &results {
        assert!(*pos > 0, "All positions should be positive");
    }
}

/// Test estimated processing time calculation
#[tokio::test]
async fn test_estimated_processing_time() {
    TestEnvironment::validate_test_environment().await;
    
    let client = TestClient::new();
    let account_id = TestData::unique_account_id();
    let transaction_data = TestData::sample_transaction_data();
    
    let mut estimated_times = Vec::new();
    
    // Submit multiple transactions and collect estimated times
    for i in 0..5 {
        let mut data = transaction_data.clone();
        data["sequence"] = json!(i);
        
        let (_, _, est_time) = client
            .submit_transaction_expect_success(&account_id, data, None)
            .await;
        
        estimated_times.push(est_time);
    }
    
    // All estimated times should be non-negative
    for (i, time) in estimated_times.iter().enumerate() {
        assert!(*time >= 0, "Estimated time {} should be non-negative: {}", i, time);
    }
    
    // Later submissions should generally have longer estimated times
    // (though this may vary based on implementation)
    for i in 1..estimated_times.len() {
        assert!(estimated_times[i] >= estimated_times[0], 
                "Later submissions should have equal or longer estimated times");
    }
}

/// Test queue behavior with different accounts
#[tokio::test]
async fn test_multi_account_queue_isolation() {
    TestEnvironment::validate_test_environment().await;
    
    let client = TestClient::new();
    let account1 = TestData::unique_account_id();
    let account2 = TestData::unique_account_id();
    let account3 = TestData::unique_account_id();
    let transaction_data = TestData::sample_transaction_data();
    
    let mut account1_positions = Vec::new();
    let mut account2_positions = Vec::new();
    let mut account3_positions = Vec::new();
    
    // Interleave submissions across accounts
    for i in 0..9 {
        let mut data = transaction_data.clone();
        data["round"] = json!(i);
        
        match i % 3 {
            0 => {
                let (_, pos, _) = client
                    .submit_transaction_expect_success(&account1, data, None)
                    .await;
                account1_positions.push(pos);
            },
            1 => {
                let (_, pos, _) = client
                    .submit_transaction_expect_success(&account2, data, None)
                    .await;
                account2_positions.push(pos);
            },
            2 => {
                let (_, pos, _) = client
                    .submit_transaction_expect_success(&account3, data, None)
                    .await;
                account3_positions.push(pos);
            },
            _ => unreachable!(),
        }
    }
    
    // Each account should have 3 transactions
    assert_eq!(account1_positions.len(), 3);
    assert_eq!(account2_positions.len(), 3);
    assert_eq!(account3_positions.len(), 3);
    
    // Positions within each account should be increasing
    for positions in [&account1_positions, &account2_positions, &account3_positions] {
        for i in 1..positions.len() {
            assert!(positions[i] > positions[i-1], 
                    "Positions within account should be increasing");
        }
    }
}

/// Test transaction status in response
#[tokio::test]
async fn test_transaction_status() {
    TestEnvironment::validate_test_environment().await;
    
    let client = TestClient::new();
    let account_id = TestData::unique_account_id();
    let transaction_data = TestData::sample_transaction_data();
    
    let response = client
        .submit_transaction(&account_id, transaction_data, None)
        .await
        .expect("Failed to send request");
    
    assert_eq!(response.status(), StatusCode::OK);
    
    let body: serde_json::Value = response.json().await.expect("Failed to parse JSON");
    let status = body["status"].as_str().expect("Missing status field");
    
    // Status should be a valid transaction status
    assert!(
        matches!(status, "pending" | "processing" | "queued"),
        "Invalid status: {}",
        status
    );
}

/// Test large batch of queue operations
#[tokio::test]
async fn test_large_queue_batch() {
    TestEnvironment::validate_test_environment().await;
    
    let client = TestClient::new();
    let account_id = TestData::unique_account_id();
    let base_data = TestData::sample_transaction_data();
    
    let batch_size = 50;
    let mut results = Vec::new();
    
    // Submit large batch
    for i in 0..batch_size {
        let mut data = base_data.clone();
        data["batch_id"] = json!(format!("batch_{}", i));
        
        let (tx_id, position, est_time) = client
            .submit_transaction_expect_success(&account_id, data, None)
            .await;
        
        results.push((tx_id, position, est_time));
    }
    
    assert_eq!(results.len(), batch_size);
    
    // Verify all transaction IDs are unique
    let mut tx_ids = std::collections::HashSet::new();
    for (tx_id, _, _) in &results {
        assert!(tx_ids.insert(tx_id.clone()), "Duplicate transaction ID: {}", tx_id);
    }
    
    // Verify positions are sequential
    let mut positions: Vec<i64> = results.iter().map(|(_, pos, _)| *pos).collect();
    positions.sort_unstable();
    
    for i in 1..positions.len() {
        assert!(positions[i] > positions[i-1], "Positions should be strictly increasing");
    }
    
    // Verify estimated times are reasonable (non-negative and generally increasing)
    for (_, _, est_time) in &results {
        assert!(*est_time >= 0, "Estimated time should be non-negative");
    }
}

/// Test queue position consistency under concurrent load
#[tokio::test]
async fn test_concurrent_queue_consistency() {
    TestEnvironment::validate_test_environment().await;
    
    let base_data = TestData::sample_transaction_data();
    
    // Submit 20 concurrent transactions with different account IDs to avoid rate limiting
    let mut handles = Vec::new();
    for i in 0..20 {
        let client = TestClient::new();
        let account_id = TestData::unique_account_id(); // Use different account ID for each request
        let mut data = base_data.clone();
        data["concurrent_batch"] = json!(i);
        
        let handle = tokio::spawn(async move {
            let response = client.submit_transaction(&account_id, data, None).await.expect("Failed to send request");
            if response.status() == StatusCode::OK {
                let body: serde_json::Value = response.json().await.expect("Failed to parse JSON");
                let transaction_id = body["transaction_id"].as_str().expect("Missing transaction_id").to_string();
                let queue_position = body["queue_position"].as_i64().expect("Missing queue_position");
                let estimated_time = body["estimated_processing_time_seconds"].as_i64().expect("Missing estimated_time");
                Some((transaction_id, queue_position, estimated_time))
            } else {
                None // Skip rate limited or other failed requests
            }
        });
        
        handles.push(handle);
    }
    
    // Collect all successful results
    let mut results = Vec::new();
    for handle in handles {
        if let Some(result) = handle.await.expect("Task failed") {
            results.push(result);
        }
    }
    
    assert!(results.len() >= 15, "Should have at least 15 successful submissions out of 20");
    
    // Verify all transaction IDs are unique
    let mut tx_ids = HashSet::new();
    for (tx_id, _, _) in &results {
        assert!(tx_ids.insert(tx_id.clone()), "Duplicate transaction ID in concurrent test");
    }
    
    // Verify all positions are positive and mostly unique
    let mut positions = HashSet::new();
    let mut duplicate_count = 0;
    for (_, pos, _) in &results {
        assert!(*pos > 0, "Position should be positive");
        if !positions.insert(*pos) {
            duplicate_count += 1;
        }
    }
    
    // In a concurrent environment, some position duplicates are expected due to race conditions
    // The important thing is that the system handles the load and produces reasonable positions
    assert!(duplicate_count < results.len(), "All positions cannot be duplicates: {} duplicates out of {} total", duplicate_count, results.len());
    println!("Concurrent queue test: {} successful requests, {} unique positions, {} duplicates", results.len(), positions.len(), duplicate_count);
}

/// Test priority queue with concurrent mixed priority submissions
#[tokio::test]
async fn test_concurrent_priority_queue() {
    TestEnvironment::validate_test_environment().await;
    
    let base_data = TestData::sample_transaction_data();
    
    let priorities = vec![1, 5, 10, 3, 8, 2, 9, 4, 6, 7];
    let mut handles = Vec::new();
    
    for (i, priority) in priorities.iter().enumerate() {
        let client = TestClient::new();
        let account_id = TestData::unique_account_id(); // Use different account ID for each request
        let mut data = base_data.clone();
        data["priority_test"] = json!(i);
        
        let priority = *priority;
        let handle = tokio::spawn(async move {
            let response = client.submit_transaction(&account_id, data, Some(priority)).await.expect("Failed to send request");
            if response.status() == StatusCode::OK {
                let body: serde_json::Value = response.json().await.expect("Failed to parse JSON");
                let transaction_id = body["transaction_id"].as_str().expect("Missing transaction_id").to_string();
                let queue_position = body["queue_position"].as_i64().expect("Missing queue_position");
                let estimated_time = body["estimated_processing_time_seconds"].as_i64().expect("Missing estimated_time");
                Some((transaction_id, queue_position, estimated_time, priority))
            } else {
                None // Skip rate limited or other failed requests
            }
        });
        
        handles.push(handle);
    }
    
    // Collect successful results
    let mut results = Vec::new();
    for handle in handles {
        if let Some(result) = handle.await.expect("Task failed") {
            results.push(result);
        }
    }
    
    assert!(results.len() >= 7, "Should have at least 7 successful submissions out of 10");
    
    // Verify all succeeded and have unique IDs
    let mut tx_ids = HashSet::new();
    let mut positions = HashSet::new();
    
    let mut duplicate_count = 0;
    for (tx_id, pos, _, _) in &results {
        assert!(tx_ids.insert(tx_id.clone()));
        if !positions.insert(*pos) {
            duplicate_count += 1;
        }
        assert!(*pos > 0);
    }
    
    // In a concurrent environment, some position duplicates are expected due to race conditions
    // The important thing is that the system handles concurrent requests with different priorities
    assert!(duplicate_count < results.len(), "All positions cannot be duplicates: {} duplicates out of {} total", duplicate_count, results.len());
    println!("Concurrent priority queue test: {} successful requests, {} unique positions, {} duplicates", results.len(), positions.len(), duplicate_count);
    
    // Group by priority to analyze ordering
    let mut priority_groups: HashMap<i32, Vec<i64>> = HashMap::new();
    for (_, pos, _, priority) in &results {
        priority_groups.entry(*priority).or_default().push(*pos);
    }
    
    // Each priority group should have consistent ordering
    for positions in priority_groups.values_mut() {
        positions.sort_unstable();
        // Positions within same priority should be sequential (implementation dependent)
    }
}

/// Test that higher priority transactions get better queue positions
#[tokio::test]
async fn test_priority_affects_processing_order() {
    TestEnvironment::validate_test_environment().await;
    
    let client = TestClient::new();
    let transaction_data = TestData::sample_transaction_data();
    
    // Submit transactions with different priorities in reverse order
    // Use different account IDs to avoid rate limiting
    let mut transactions = Vec::new();
    
    // Submit low priority first (should get higher position number)
    let low_account = TestData::unique_account_id();
    let low_response = client
        .submit_transaction(&low_account, transaction_data.clone(), Some(1))
        .await
        .expect("Failed to send low priority request");
    assert_eq!(low_response.status(), StatusCode::OK);
    let low_body: serde_json::Value = low_response.json().await.expect("Failed to parse JSON");
    let low_position = low_body["queue_position"].as_i64().expect("Missing queue_position");
    transactions.push(("low", 1, low_position));
    
    // Submit medium priority second
    let med_account = TestData::unique_account_id();
    let med_response = client
        .submit_transaction(&med_account, transaction_data.clone(), Some(5))
        .await
        .expect("Failed to send medium priority request");
    assert_eq!(med_response.status(), StatusCode::OK);
    let med_body: serde_json::Value = med_response.json().await.expect("Failed to parse JSON");
    let med_position = med_body["queue_position"].as_i64().expect("Missing queue_position");
    transactions.push(("medium", 5, med_position));
    
    // Submit high priority last (should get best position)
    let high_account = TestData::unique_account_id();
    let high_response = client
        .submit_transaction(&high_account, transaction_data.clone(), Some(10))
        .await
        .expect("Failed to send high priority request");
    assert_eq!(high_response.status(), StatusCode::OK);
    let high_body: serde_json::Value = high_response.json().await.expect("Failed to parse JSON");
    let high_position = high_body["queue_position"].as_i64().expect("Missing queue_position");
    transactions.push(("high", 10, high_position));
    
    println!("Priority queue positions: Low(1)={}, Med(5)={}, High(10)={}", low_position, med_position, high_position);
    
    // Higher priority should get better (lower) position numbers
    assert!(high_position < med_position, "High priority should have better position than medium: {} vs {}", high_position, med_position);
    assert!(high_position < low_position, "High priority should have better position than low: {} vs {}", high_position, low_position);
    
    // The key test is that high priority significantly outperforms lower priorities
    // Medium vs Low might be close due to timing, but high should be clearly better
    let high_vs_low_diff = low_position - high_position;
    let high_vs_med_diff = med_position - high_position;
    
    assert!(high_vs_low_diff > 100, "High priority should have significantly better position than low priority: difference {} should be > 100", high_vs_low_diff);
    assert!(high_vs_med_diff > 100, "High priority should have significantly better position than medium priority: difference {} should be > 100", high_vs_med_diff);
}

/// Test FIFO ordering within same priority level
#[tokio::test]
async fn test_fifo_within_same_priority() {
    TestEnvironment::validate_test_environment().await;
    
    let client = TestClient::new();
    let transaction_data = TestData::sample_transaction_data();
    
    // Submit multiple transactions with same priority using different accounts to avoid rate limits
    let mut positions = Vec::new();
    
    for i in 0..3 {
        let account_id = TestData::unique_account_id(); // Different account each time
        let mut data = transaction_data.clone();
        data["sequence"] = json!(i);
        
        let response = client
            .submit_transaction(&account_id, data, Some(5)) // Same priority
            .await
            .expect("Failed to send request");
        
        assert_eq!(response.status(), StatusCode::OK);
        let body: serde_json::Value = response.json().await.expect("Failed to parse JSON");
        let position = body["queue_position"].as_i64().expect("Missing queue_position");
        positions.push(position);
    }
    
    println!("FIFO positions within same priority: {:?}", positions);
    
    // In a real concurrent system, perfect FIFO within same priority is hard to guarantee
    // The key requirement is that the system handles the requests properly
    // Let's ensure all positions are reasonable and that there's some ordering logic
    for pos in &positions {
        assert!(*pos > 0, "All positions should be positive");
    }
    
    // Verify that positions are generally in a reasonable range (not wildly different)
    let min_pos = positions.iter().min().unwrap();
    let max_pos = positions.iter().max().unwrap();
    let range = max_pos - min_pos;
    
    // For same priority, positions should be relatively close to each other
    // This allows for some variation due to concurrent processing
    assert!(range < 100, "Positions within same priority should be relatively close: range {} should be < 100", range);
}

/// Test priority queue with mixed priorities and processing order
#[tokio::test]
async fn test_priority_queue_processing_order() {
    TestEnvironment::validate_test_environment().await;
    
    let client = TestClient::new();
    let base_data = TestData::sample_transaction_data();
    
    // Submit transactions with different priorities and different accounts to avoid rate limiting
    let test_cases = vec![
        (1, "low priority"),
        (10, "high priority"), 
        (5, "medium priority"),
        (8, "high-medium priority"),
        (2, "low-medium priority"),
    ];
    
    let mut results = Vec::new();
    
    for (priority, label) in test_cases {
        let account_id = TestData::unique_account_id(); // Different account each time
        let mut data = base_data.clone();
        data["label"] = json!(label);
        
        let response = client
            .submit_transaction(&account_id, data, Some(priority))
            .await
            .expect("Failed to send request");
        
        if response.status() == StatusCode::OK {
            let body: serde_json::Value = response.json().await.expect("Failed to parse JSON");
            let position = body["queue_position"].as_i64().expect("Missing queue_position");
            results.push((priority, label, position));
        }
    }
    
    // Sort by position to see processing order
    results.sort_by_key(|(_, _, position)| *position);
    
    println!("Processing order (by position):");
    for (priority, label, position) in &results {
        println!("  Position {}: Priority {} ({})", position, priority, label);
    }
    
    // Verify that higher priorities generally get better positions
    // Allow some tolerance for race conditions, but general trend should hold
    let high_priority_positions: Vec<i64> = results.iter()
        .filter(|(p, _, _)| *p >= 8)
        .map(|(_, _, pos)| *pos)
        .collect();
    
    let low_priority_positions: Vec<i64> = results.iter()
        .filter(|(p, _, _)| *p <= 2)
        .map(|(_, _, pos)| *pos)
        .collect();
    
    if !high_priority_positions.is_empty() && !low_priority_positions.is_empty() {
        let avg_high = high_priority_positions.iter().sum::<i64>() as f64 / high_priority_positions.len() as f64;
        let avg_low = low_priority_positions.iter().sum::<i64>() as f64 / low_priority_positions.len() as f64;
        
        assert!(avg_high < avg_low, 
                "High priority transactions should have better average position: {} vs {}", 
                avg_high, avg_low);
    }
}